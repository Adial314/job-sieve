{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Sieve\n",
    "---\n",
    "\n",
    "Development documentation for the screen scraping of multiple job boards for useful statistics, filtered high-value prospects, and correlative analytics.\n",
    "\n",
    "---\n",
    "\n",
    "## <a name=\"toc\"></a> Table of Contents\n",
    "1. [Proof of Concept](#poc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"poc\"></a> [Proof of Concept](#toc)\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- LOAD DEPENDENCIES -------------------- #\n",
    "\n",
    "# Environment hard reset\n",
    "%reset -f\n",
    "\n",
    "# Standard math and data libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries for scraping\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import lxml.html as lh\n",
    "import ssl\n",
    "\n",
    "# Date time for date operations\n",
    "import datetime\n",
    "\n",
    "# Levenshtein fuzzy comparisons\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Import string cleaning functions\n",
    "import re\n",
    "\n",
    "# Flask support\n",
    "from flask import request, jsonify\n",
    "\n",
    "# Configure paths\n",
    "from pathlib import Path\n",
    "# data_path = Path('Datasets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=CCNA&l=Albuquerque'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- FORM AND RUN QUERY -------------------- #\n",
    "\n",
    "def form_query(keywords, location=None):\n",
    "    \n",
    "    base = \"https://www.indeed.com/jobs?\"\n",
    "    \n",
    "    keyword_chain = str()\n",
    "    for keyword in keywords:\n",
    "        if len(keyword_chain) == 0:\n",
    "            keyword_chain += \"q=\" + keyword\n",
    "        else:\n",
    "            keyword_chain += \"+\" + keyword\n",
    "\n",
    "    if location:\n",
    "        location = \"&l=\" + location\n",
    "        \n",
    "    return base + keyword_chain + location\n",
    "\n",
    "\n",
    "# TEST #\n",
    "\n",
    "keywords = [\"CCNA\"]\n",
    "location =  \"Albuquerque\"\n",
    "\n",
    "form_query(keywords, location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- RUN QUERY -------------------- #\n",
    "\n",
    "def run_query(query):\n",
    "    response = requests.get(query)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    return soup.prettify()\n",
    "\n",
    "\n",
    "# TEST #\n",
    "\n",
    "keywords = [\"CCNA\"]\n",
    "location =  \"Albuquerque\"\n",
    "\n",
    "query = form_url(keywords, location)\n",
    "html = run_query(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- PARSE HTML -------------------- #\n",
    "\n",
    "keywords = [\"CCNA\"]\n",
    "location =  \"Albuquerque\"\n",
    "\n",
    "query = form_url(keywords, location)\n",
    "\n",
    "# ---------- #\n",
    "\n",
    "# def parse_html(query):\n",
    "    \n",
    "# For ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Making the website believe that you are accessing it using a Mozilla browser\n",
    "req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "webpage = urlopen(req).read()\n",
    "\n",
    "# Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "soup = BeautifulSoup(webpage, 'html.parser')\n",
    "html = soup.prettify('utf-8')\n",
    "profile = {}\n",
    "trading = {}\n",
    "fundamentals = {}\n",
    "\n",
    "# Iterate through cards\n",
    "for td in soup.findAll(\"td\", attrs={\"id\": \"resultsCol\"}):\n",
    "    for card in td.findAll(\"div\", attrs={\"class\": \"jobsearch-SerpJobCard unifiedRow row result\"}):\n",
    "        \n",
    "        # Parse title\n",
    "        title = parse_card_title(card)\n",
    "\n",
    "# ---------- #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   HELPER   #\n",
    "# ---------- #\n",
    "\n",
    "def parse_card_title(card):\n",
    "    h2 = card.findAll(\"h2\", attrs={\"class\": \"title\"})[0]\n",
    "    title = h2.findAll(\"a\", attrs={\"class\": \"jobtitle turnstileLink\"})[0]\n",
    "    return title.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseHTML(query):\n",
    "    \n",
    "    # For ignoring SSL certificate errors\n",
    "    ctx = ssl.create_default_context()\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    # Making the website believe that you are accessing it using a Mozilla browser\n",
    "    req = Request(query, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    # Creating a BeautifulSoup object of the HTML page for easy extraction of data.\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    html = soup.prettify('utf-8')\n",
    "    profile = {}\n",
    "    trading = {}\n",
    "    fundamentals = {}\n",
    "    \n",
    "    # TRADING\n",
    "    \n",
    "    # Previous Close\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PREV_CLOSE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Previous Close'] = span.text.strip()\n",
    "    \n",
    "    # Open Value\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'OPEN-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Open'] = span.text.strip()\n",
    "\n",
    "    # Present Value\n",
    "    for span in soup.findAll('span', attrs={'class': 'Trsdu(0.3s) Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(b)'}):\n",
    "        trading['Present Value'] = span.text.strip()\n",
    "            \n",
    "    # Bid\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BID-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Bid'] = span.text.strip()\n",
    "\n",
    "    # Ask\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ASK-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Ask'] = span.text.strip()\n",
    "\n",
    "    # Present Growth\n",
    "    for div in soup.findAll('div', attrs={'class': 'D(ib) Va(t)'}):\n",
    "        for span in div.findAll('span', recursive=False):\n",
    "            profile['Present Growth'] = span.text.strip()\n",
    "\n",
    "    # Day's Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DAYS_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Day Range'] = span.text.strip()\n",
    "\n",
    "    # Fifty-two Week Range\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'FIFTY_TWO_WK_RANGE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Fifty-Two Week Range'] = span.text.strip()\n",
    "\n",
    "    # Trading Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'TD_VOLUME-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Day Volume'] = span.text.strip()\n",
    "\n",
    "    # Average 3M Volume\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            trading['Average 3M Volume'] = span.text.strip()\n",
    "            \n",
    "    # FUNDAMENTALS\n",
    "\n",
    "    # Market Capitalization\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'MARKET_CAP-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Market Capitalization'] = span.text.strip()\n",
    "\n",
    "    # Beta 3Y\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'BETA_3Y-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Beta 3Y'] = span.text.strip()\n",
    "\n",
    "    # PE Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'PE_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['PE Ratio'] = span.text.strip()\n",
    "\n",
    "    # EPS Ratio\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EPS_RATIO-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['EPS Ratio'] = span.text.strip()\n",
    "\n",
    "    # Earnings Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EARNINGS_DATE-value'}):\n",
    "        trading['Earnings Date'] = []\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Earnings Date'] = span.text.strip()\n",
    "\n",
    "    # Dividend and Yield\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'DIVIDEND_AND_YIELD-value'}):\n",
    "        fundamentals['Dividend'] = td.text.strip().split()[0]\n",
    "        fundamentals['Dividend Yield'] = td.text.strip().split()[1].translate({ord(i): None for i in '()%'})\n",
    "\n",
    "    # Ex Dividend Date\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'EX_DIVIDEND_DATE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['Ex Dividend Rate'] = span.text.strip()\n",
    "\n",
    "    # One Year Target Price\n",
    "    for td in soup.findAll('td', attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}):\n",
    "        for span in td.findAll('span', recursive=False):\n",
    "            fundamentals['One Year Target Price'] = span.text.strip()\n",
    "\n",
    "    # Other Details\n",
    "    profile['Trading'] = trading\n",
    "    profile['Fundamental'] = fundamentals\n",
    "    \n",
    "    # Return full profile\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
